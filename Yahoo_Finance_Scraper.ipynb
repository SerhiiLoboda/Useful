{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yahoo Finance Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerhiiLoboda/Useful/blob/master/Yahoo_Finance_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2AioIY_YEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv \n",
        "import pandas as pd \n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeqWwaVoV0mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def for getting data from earnings page, including link to company page.In default today earning but accepts list of dates \n",
        "def earningsgeter (dates=datetime.date.today()):\n",
        "  earnings=pd.DataFrame({'Date':[],\"Symbol\": [], \"Link\": [], \"Companie\": [], \"Earnings_Call_Time\": [], \"EPS_Estimate\": [],'EPS_Estimate': [] ,\"Reported_EPS\": [],\"Surprise(%)\": []})\n",
        "  for date in dates:\n",
        "    Symbols=[]\n",
        "    Links=[]\n",
        "    Companies=[]\n",
        "    Earnings_Call_Times =[]\n",
        "    EPS_Estimates   = []\n",
        "    Reported_EPSs   =[]\n",
        "    Surprises=[]\n",
        " \n",
        "    EarningsUrl = \"https://finance.yahoo.com/calendar/earnings?day=\"+str(date)\n",
        "    r= requests.get(EarningsUrl)\n",
        "    data=r.text\n",
        "    soup=BeautifulSoup(data)\n",
        "    for listing in soup.find_all('tr'):\n",
        "      for Symbol in listing.find_all('td', attrs={'aria-label':\"Symbol\" }):\n",
        "        Symbols.append(Symbol.text)\n",
        "        for a in Symbol.find_all('a', href=True):\n",
        "          Links.append('https://finance.yahoo.com'+a['href'])\n",
        "      for Company in listing.find_all('td', attrs={'aria-label':\"Company\" }):\n",
        "        Companies.append(Company.text)\n",
        "      for Earnings_Call_Time in listing.find_all('td', attrs={'aria-label':\"Earnings Call Time\" }):\n",
        "        Earnings_Call_Times.append(Earnings_Call_Time.text)\n",
        "      for EPS_Estimate in listing.find_all('td', attrs={'aria-label':\"EPS Estimate\" }):\n",
        "        EPS_Estimates.append(EPS_Estimate.text)\n",
        "      for Reported_EPS in listing.find_all('td', attrs={'aria-label':\"Reported EPS\" }):\n",
        "        Reported_EPSs.append(Reported_EPS.text)\n",
        "      for Surprise in listing.find_all('td', attrs={'aria-label':\"Surprise(%)\" }):\n",
        "        Surprises.append(Surprise.text)    \n",
        "    earning=pd.DataFrame({\"Symbol\": Symbols, \"Link\": Links, \"Companie\": Companies, \"Earnings_Call_Time\": Earnings_Call_Times, \"EPS_Estimate\": EPS_Estimates,'EPS_Estimate': EPS_Estimates ,\"Reported_EPS\": Reported_EPSs,\"Surprise(%)\": Surprises})\n",
        "    earning['Date']=date\n",
        "    earnings=earnings.append(earning)\n",
        "  return(earnings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpGrTifhFGM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newssgeter (CompanieLink,Companie, curentnewslinks=[]):\n",
        "  r= requests.get(CompanieLink)\n",
        "  data=r.text\n",
        "  soup=BeautifulSoup(data)\n",
        "  newLinks=[]\n",
        "  newstimes=[]\n",
        "  newsHeaders=[]\n",
        "  newsTexts=[]\n",
        "  for listing in soup.find_all('h3'):\n",
        "    for a in listing.find_all('a', href=True):\n",
        "      if not a['href'].lstrip().startswith('https') :\n",
        "        r2= requests.get('https://finance.yahoo.com'+a['href'])\n",
        "        newsLink='https://finance.yahoo.com'+a['href']\n",
        "      else:\n",
        "        r2= requests.get(a['href'])\n",
        "        newsLink=a['href']           \n",
        "      data2=r2.text\n",
        "      soup2=BeautifulSoup(data2)\n",
        "      try:\n",
        "        newstime = datetime.datetime.strptime(soup2.find('time').attrs['datetime'], '%Y-%m-%dT%H:%M:%S.%fZ' )\n",
        "        newLinks.append(newsLink)\n",
        "        newstimes.append(newstime)\n",
        "        newsHeaders.append(soup2.find('title').text)\n",
        "        newsText=\"\"\n",
        "        for newsPart in soup2.find_all('p',attrs={'class':\"canvas-atom\", 'type':\"text\"  }):\n",
        "          newsText=newsText +'\\n '+newsPart.text\n",
        "        for table in soup.find_all('table'):\n",
        "          newsText=newsText +' <table> '\n",
        "          for tr in table.find_all('tr'):\n",
        "            newsText=newsText +'<tr> '\n",
        "            for td in tr.find_all('td'):\n",
        "              newsText=newsText +'<td> '+tr.text+' </td>'\n",
        "            newsText=newsText +' </tr>'\n",
        "          newsText=newsText +' </table>'\n",
        "          newsText=newsText +'\\n '+table.text\n",
        "        newsTexts.append(newsText)\n",
        "      except:\n",
        "        continue     \n",
        "  news=pd.DataFrame({\"news time\": newstimes, \"news header\": newsHeaders, \"news text\": newsTexts,\"news link\": newLinks })\n",
        "  news['Companie']=Companie\n",
        "  return(news) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EFwuQ9ChXAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set dates for for financial reports period\n",
        "start_date = datetime.datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
        "end_date = datetime.datetime.strptime('2019-01-05', '%Y-%m-%d')\n",
        "earnings = earningsgeter([datetime.date.fromordinal(i) for i in range(start_date.toordinal(), end_date.toordinal())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-KbSzBW5Zu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get list of companies, create dataframe for collected news\n",
        "complist = earnings[['Link','Companie']].drop_duplicates().reset_index(drop=True)\n",
        "aggNews=pd.DataFrame({\"news time\": [], \"news header\": [], \"news text\": [],\"news link\": [],\"Companie\": []})\n",
        "#comppart=complist.iloc[:]\n",
        "for line in complist.itertuples(name='Pandas'):   #comppart.itertuples(name='Pandas'):  \n",
        "  news= newssgeter (line[1], line[2],aggNews['news link'].loc[aggNews[\"Companie\"]==line[2]])\n",
        "  aggNews=aggNews.append(news)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}